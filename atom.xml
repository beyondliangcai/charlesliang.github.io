<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Charles</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-09-06T13:49:00.866Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Charles</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>charles blog menu</title>
    <link href="http://yoursite.com/2018/09/06/menu/"/>
    <id>http://yoursite.com/2018/09/06/menu/</id>
    <published>2018-09-06T12:19:32.000Z</published>
    <updated>2018-09-06T13:49:00.866Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近在学习AI相关的知识，学了这么长时间总感觉前面的东西又忘了，而且我觉得只要写不出来的算法都是没有搞懂的，所以从今天开始写博客,复习学过的AI相关的知识，大概先从以下三个方向写：</p></blockquote><h2 id="1-机器学习篇"><a href="#1-机器学习篇" class="headerlink" title="1.机器学习篇"></a>1.机器学习篇</h2><blockquote><p>机器学习片篇基本上按照李航老师和Andrew Ng 的顺序写分类和聚类的算法</p><ul><li>1.监督学习篇<ul><li>1.KNN</li><li>2.logistic regession</li></ul></li><li>2.非监督学习篇</li></ul></blockquote><h2 id="2-深度学习"><a href="#2-深度学习" class="headerlink" title="2.深度学习"></a>2.深度学习</h2><ul><li>1.卷积神经网络</li><li>2.递归神经网络</li></ul><h2 id="3-NLP篇"><a href="#3-NLP篇" class="headerlink" title="3.NLP篇"></a>3.NLP篇</h2><ul><li>1.概率图模型</li><li>2.汉语分词</li><li>3.句法分析</li><li>4.语义分析</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;最近在学习AI相关的知识，学了这么长时间总感觉前面的东西又忘了，而且我觉得只要写不出来的算法都是没有搞懂的，所以从今天开始写博客,复习学过的AI相关的知识，大概先从以下三个方向写：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-机器学习篇
      
    
    </summary>
    
      <category term="目录" scheme="http://yoursite.com/categories/%E7%9B%AE%E5%BD%95/"/>
    
    
      <category term="menu" scheme="http://yoursite.com/tags/menu/"/>
    
  </entry>
  
  <entry>
    <title>机器学习分类算法一：逻辑回归（logistic regression）</title>
    <link href="http://yoursite.com/2016/01/15/logistic-md/"/>
    <id>http://yoursite.com/2016/01/15/logistic-md/</id>
    <published>2016-01-15T12:19:32.000Z</published>
    <updated>2018-09-06T15:58:20.747Z</updated>
    
    <content type="html"><![CDATA[<h2 id="逻辑回归（logistic-regression）"><a href="#逻辑回归（logistic-regression）" class="headerlink" title="逻辑回归（logistic regression）"></a>逻辑回归（logistic regression）</h2><blockquote><p>机器学习主要解决两个方面的问题：分类和聚类，或者叫监督学习和非监督学习。所谓分类通俗来讲指的是训练集中的样本知道y的值（也就是结果），例如一个西瓜的例子：现在想训练一个模型f来分类西瓜甜还是不甜，我们就找一批西瓜（训练集），然后我们就观察这批西瓜，发现（根茎大，皮绿，甜），那么根茎，皮就是特征X，甜和不甜就是分类的结果Y，因为训练集里面知道了Y的值，这种就是分类，如果我们不知道Y的值，只想把根茎大，皮绿的西瓜放到一起，其他的放到另一边，这种就是聚类。对于机器学习来说，如何找到模型f是关键问题，逻辑回归就是其中一种比较简单的线性模型。</p></blockquote><h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>我们高中或者大学可能已经学过了最小二乘法，这里简单的复习一下，最小二乘法也是逻辑回归的基础。<br><img src="pic/regression.png" alt="Alt text" title="least_square"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;逻辑回归（logistic-regression）&quot;&gt;&lt;a href=&quot;#逻辑回归（logistic-regression）&quot; class=&quot;headerlink&quot; title=&quot;逻辑回归（logistic regression）&quot;&gt;&lt;/a&gt;逻辑回归（logist
      
    
    </summary>
    
      <category term="classification" scheme="http://yoursite.com/categories/classification/"/>
    
    
      <category term="最小二乘" scheme="http://yoursite.com/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98/"/>
    
      <category term="逻辑回归" scheme="http://yoursite.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
</feed>
